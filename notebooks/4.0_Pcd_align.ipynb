{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import os\n",
    "import rootutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "\n",
    "rootutils.setup_root(\n",
    "    os.path.abspath(''), indicator=['.git', 'pyproject.toml'], pythonpath=True\n",
    ")\n",
    "\n",
    "from src.stereo_calibrate import (\n",
    "    read_camera_intrinsics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb564776",
   "metadata": {},
   "source": [
    "#### Load pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pcd = o3d.io.read_point_cloud('../output/pcd/20250429_105703_0.ply')\n",
    "target_left_img = cv2.imread('../data/left/left_20250429_105703_0.png')\n",
    "\n",
    "source_pcd = o3d.io.read_point_cloud('../output/pcd/20250429_110523_21.ply')\n",
    "source_left_img = cv2.imread('../data/left/left_20250429_110523_21.png')\n",
    "source_disp = np.load('../output/disp/20250429_110523_21.npy')\n",
    "\n",
    "# Read camera intrinsics\n",
    "K, distance_between_cameras = read_camera_intrinsics(\n",
    "    '../camera_configs/left_camera_intrinsics.xml'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e1575",
   "metadata": {},
   "source": [
    "#### Filter pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65447453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(pcd: o3d.geometry.PointCloud,\n",
    "                    method: str = 'statistical',\n",
    "                    nb_neighbors: int = 5,\n",
    "                    std_ratio: float = 3.0,\n",
    "                    radius: float = 0.05,\n",
    "                    min_neighbors: int = 5) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"\n",
    "    Removes outlier points from a point cloud using statistical or radius method.\n",
    "    \n",
    "    Args:\n",
    "        pcd: Input point cloud.\n",
    "        method: 'statistical' or 'radius'.\n",
    "        nb_neighbors: For statistical — number of neighbors to consider.\n",
    "        std_ratio: For statistical — threshold based on standard deviation.\n",
    "        radius: For radius — radius within which neighbors must exist.\n",
    "        min_neighbors: For radius — minimum number of neighbors within the radius.\n",
    "    \n",
    "    Returns:\n",
    "        Filtered point cloud with outliers removed.\n",
    "    \"\"\"\n",
    "    if method == 'statistical':\n",
    "        cl, ind = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors,\n",
    "                                                 std_ratio=std_ratio)\n",
    "    elif method == 'radius':\n",
    "        cl, ind = pcd.remove_radius_outlier(nb_points=min_neighbors,\n",
    "                                            radius=radius)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method: choose 'statistical' or 'radius'\")\n",
    "    \n",
    "    return cl\n",
    "\n",
    "def remove_small_clusters(pcd: o3d.geometry.PointCloud,\n",
    "                          voxel_size: float = 0.01,\n",
    "                          min_cluster_size: int = 100) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"\n",
    "    Removes small connected components (e.g. stray lines) from a dense point cloud.\n",
    "\n",
    "    Args:\n",
    "        pcd: Input point cloud.\n",
    "        voxel_size: Size used to define connectivity.\n",
    "        min_cluster_size: Minimum number of points a cluster must have to be kept.\n",
    "\n",
    "    Returns:\n",
    "        Filtered point cloud with small components removed.\n",
    "    \"\"\"\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=voxel_size, min_points=5, print_progress=False))\n",
    "    max_label = labels.max()\n",
    "    print(f\"Found {max_label + 1} clusters\")\n",
    "\n",
    "    # Filter clusters by size\n",
    "    kept_indices = []\n",
    "    for i in range(max_label + 1):\n",
    "        indices = np.where(labels == i)[0]\n",
    "        if len(indices) >= min_cluster_size:\n",
    "            kept_indices.extend(indices)\n",
    "\n",
    "    return pcd.select_by_index(kept_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pcd = remove_small_clusters(target_pcd, voxel_size=0.01, min_cluster_size=200)\n",
    "o3d.visualization.draw_geometries([target_pcd])\n",
    "source_pcd = remove_small_clusters(source_pcd, voxel_size=0.01, min_cluster_size=200)\n",
    "o3d.visualization.draw_geometries([source_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891017b6",
   "metadata": {},
   "source": [
    "#### Align pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23083db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pointcloud(pcd, voxel_size=0.05):\n",
    "    \"\"\"Preprocess the pointcloud: downsample and estimate normals.\"\"\"\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    if not pcd_down.has_normals():\n",
    "        pcd_down.estimate_normals()\n",
    "        pcd_down.orient_normals_consistent_tangent_plane(k=30)\n",
    "    \n",
    "    return pcd_down\n",
    "\n",
    "def compute_fpfh_features(pcd, voxel_size):\n",
    "    \"\"\"Compute FPFH features for registration.\"\"\"\n",
    "    return o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100)\n",
    "    )\n",
    "\n",
    "def execute_global_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    \"\"\"Perform global registration using RANSAC.\"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    \n",
    "    # Define RANSAC parameters\n",
    "    ransac_n = 3  # Number of points to use for estimation\n",
    "    checkers = [\n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    ]\n",
    "    criteria = o3d.pipelines.registration.RANSACConvergenceCriteria(\n",
    "        max_iteration=100000,\n",
    "        confidence=0.999\n",
    "    )\n",
    "    \n",
    "    # Execute global registration\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, \n",
    "        mutual_filter=False,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=ransac_n, \n",
    "        checkers=checkers,\n",
    "        criteria=criteria\n",
    "    )\n",
    "    \n",
    "    print(f\"Global registration result: {result}\")\n",
    "    print(f\"Fitness: {result.fitness}, Inlier RMSE: {result.inlier_rmse}\")\n",
    "    return result\n",
    "\n",
    "def refine_registration(source, target, result_ransac, voxel_size):\n",
    "    \"\"\"Refine registration using ICP.\"\"\"\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    \n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=10000)\n",
    "    )\n",
    "    \n",
    "    print(f\"ICP refinement result: {result}\")\n",
    "    print(f\"Fitness: {result.fitness}, Inlier RMSE: {result.inlier_rmse}\")\n",
    "    return result\n",
    "\n",
    "def align_pointclouds(source, target, voxel_size=0.05):\n",
    "    \"\"\"Main function to align two pointclouds.\"\"\"\n",
    "    \n",
    "    # Visualize original pointclouds\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0, 0])  # Red for source\n",
    "    target_temp.paint_uniform_color([0, 1, 0])  # Green for target\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp], \n",
    "                                     window_name=\"Original Pointclouds\")\n",
    "    \n",
    "    # Preprocess pointclouds\n",
    "    source_down = preprocess_pointcloud(source, voxel_size)\n",
    "    target_down = preprocess_pointcloud(target, voxel_size)\n",
    "    \n",
    "    # Compute FPFH features\n",
    "    source_fpfh = compute_fpfh_features(source_down, voxel_size)\n",
    "    target_fpfh = compute_fpfh_features(target_down, voxel_size)\n",
    "    \n",
    "    # Global registration\n",
    "    result_ransac = execute_global_registration(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, voxel_size\n",
    "    )\n",
    "    \n",
    "    # Visualize after global registration\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(result_ransac.transformation)\n",
    "    source_temp.paint_uniform_color([1, 0, 0])  # Red for source\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    target_temp.paint_uniform_color([0, 1, 0])  # Green for target\n",
    "    print(\"Displaying alignment after global registration...\")\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp], \n",
    "                                     window_name=\"After Global Registration\")\n",
    "    \n",
    "    # Refine registration with ICP\n",
    "    result_icp = refine_registration(\n",
    "        source_down, target_down, result_ransac, voxel_size\n",
    "    )\n",
    "    \n",
    "    # Transform the original source pointcloud\n",
    "    source.transform(result_icp.transformation)\n",
    "    \n",
    "    # Visualize final result\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.paint_uniform_color([1, 0, 0])  # Red for source\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    target_temp.paint_uniform_color([0, 1, 0])  # Green for target\n",
    "    print(\"Displaying final alignment...\")\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp], \n",
    "                                     window_name=\"Final Alignment\")\n",
    "    \n",
    "    return source, result_icp.transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voxel size for downsampling\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Align pointclouds\n",
    "aligned_source, transformation = align_pointclouds(source_pcd, target_pcd, voxel_size)\n",
    "print(\"Alignment complete. Transformation matrix:\")\n",
    "print(transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63d7c5",
   "metadata": {},
   "source": [
    "#### Align left images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f40d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_to_depth(disparity: np.ndarray, K: np.ndarray, baseline: float) -> np.ndarray:\n",
    "    \"\"\"Convert disparity map to depth map.\"\"\"\n",
    "    f = K[0, 0]  # fx\n",
    "    depth = (f * baseline) / (disparity + 1e-6)\n",
    "    return depth\n",
    "\n",
    "def generate_3d_points(depth: np.ndarray, K: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Back-project depth map to 3D points in camera coordinate frame.\"\"\"\n",
    "    h, w = depth.shape\n",
    "    u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    z = depth\n",
    "    x = (u - K[0, 2]) * z / K[0, 0]\n",
    "    y = (v - K[1, 2]) * z / K[1, 1]\n",
    "    points_3d = np.stack((x, y, z, np.ones_like(z)), axis=-1).reshape(-1, 4).T  # shape: (4, N)\n",
    "    return points_3d\n",
    "\n",
    "def transform_points(points_3d: np.ndarray, transformation: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply a 4x4 transformation to 3D points.\"\"\"\n",
    "    transformed = transformation @ points_3d\n",
    "    return transformed\n",
    "\n",
    "def project_3d_to_2d(points_3d: np.ndarray, K: np.ndarray) -> tuple:\n",
    "    \"\"\"Project 3D points back to 2D image coordinates.\"\"\"\n",
    "    points_3d /= points_3d[2]  # normalize by Z\n",
    "    u_proj = (K[0, 0] * points_3d[0]) + K[0, 2]\n",
    "    v_proj = (K[1, 1] * points_3d[1]) + K[1, 2]\n",
    "    return u_proj, v_proj\n",
    "\n",
    "def warp_image(\n",
    "    source_img: np.ndarray,\n",
    "    u_proj: np.ndarray,\n",
    "    v_proj: np.ndarray,\n",
    "    u_src: np.ndarray,\n",
    "    v_src: np.ndarray,\n",
    "    shape: tuple\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Generate warped image based on remapped pixel locations.\"\"\"\n",
    "    h, w = shape\n",
    "    warped = np.zeros_like(source_img)\n",
    "    \n",
    "    # Valid range mask\n",
    "    valid = (u_proj >= 0) & (u_proj < w) & (v_proj >= 0) & (v_proj < h)\n",
    "    u_proj = u_proj[valid].astype(np.int32)\n",
    "    v_proj = v_proj[valid].astype(np.int32)\n",
    "    u_src = u_src[valid]\n",
    "    v_src = v_src[valid]\n",
    "    \n",
    "    warped[v_proj, u_proj] = source_img[v_src, u_src]\n",
    "    return warped\n",
    "\n",
    "def fill_black_pixels_with_dilation(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Fill black pixels in the image using morphological dilation.\"\"\"\n",
    "    mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) == 0\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    filled = image.copy()\n",
    "    \n",
    "    for _ in range(3):\n",
    "        dilated = cv2.dilate(filled, kernel)\n",
    "        filled[mask] = dilated[mask]\n",
    "        mask = (cv2.cvtColor(filled, cv2.COLOR_BGR2GRAY) == 0)\n",
    "    \n",
    "    return filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workflow:\n",
    "1. Converting disparity to 3D\n",
    "Converts disparity values (pixel shifts between stereo images) to real-world depth (in meters).\n",
    "\n",
    "2. Applying a transformation matrix (from ICP)\n",
    "Back-projects each 2D pixel (u, v) to a 3D point (x, y, z) using the pinhole camera model.\n",
    "Applies a rigid transformation (rotation + translation) to all 3D points.\n",
    "\n",
    "3. Projecting back to 2D\n",
    "Projects 3D points back to 2D image pixels using the camera intrinsics matrix K.\n",
    "\n",
    "4. Warping the source image into the new view\n",
    "For each transformed pixel, it copies the color from the original source image into a new blank canvas.\n",
    "u_src, v_src are original pixel indices; u_proj, v_proj are where to place them after warping.\n",
    "No interpolation → this creates black holes if pixels land sparsely or collide.\n",
    "\n",
    "5. Filling in any holes caused by remapping gaps\n",
    "Fills black pixels by copying color from surrounding pixels using morphological dilation.\n",
    "\n",
    "# Inputs:\n",
    "# - source_left_img\n",
    "# - source_disp\n",
    "# - transformation (from ICP)\n",
    "# - K (camera intrinsics)\n",
    "# - baseline (in meters)\n",
    "\"\"\"\n",
    "\n",
    "fx = K[0, 0]\n",
    "T_scaled = transformation.copy()\n",
    "scale = 5\n",
    "T_scaled[:3, 3] *= scale\n",
    "\n",
    "depth = disparity_to_depth(source_disp, K, distance_between_cameras)\n",
    "points_3d = generate_3d_points(depth, K)\n",
    "transformed_points = transform_points(points_3d, T_scaled)\n",
    "u_proj, v_proj = project_3d_to_2d(transformed_points, K)\n",
    "\n",
    "h, w = source_disp.shape\n",
    "u_grid, v_grid = np.meshgrid(np.arange(w), np.arange(h))\n",
    "warped_img = warp_image(source_left_img, u_proj, v_proj, u_grid.flatten(), v_grid.flatten(), (h, w))\n",
    "warped_img = fill_black_pixels_with_dilation(warped_img)\n",
    "\n",
    "# show the warped image\n",
    "plt.imshow(cv2.cvtColor(warped_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68ddb8",
   "metadata": {},
   "source": [
    "#### Compute pcd differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pcd_differences(source: o3d.geometry.PointCloud,\n",
    "                       reference: o3d.geometry.PointCloud,\n",
    "                       max_dist: float = None) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"\n",
    "    Colors the `source` cloud based on distances to `reference`.\n",
    "    Useful for heatmap-like visualization.\n",
    "    \"\"\"\n",
    "    distances = np.asarray(source.compute_point_cloud_distance(reference))\n",
    "    if max_dist is None:\n",
    "        max_dist = np.percentile(distances, 95)  # Robust cap to remove outliers\n",
    "\n",
    "    # Normalize and convert to colormap\n",
    "    normalized = np.clip(distances / max_dist, 0, 1)\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    colors = cmap(normalized)[:, :3]  # Remove alpha\n",
    "\n",
    "    source_colored = copy.deepcopy(source)\n",
    "    source_colored.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return source_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_pcd = compute_pcd_differences(aligned_source, target_pcd, max_dist=0.01)\n",
    "o3d.visualization.draw_geometries([distance_pcd], window_name=\"Anomaly Map\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
